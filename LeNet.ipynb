{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#clone repo\n",
        "!git clone https://github.com/mattwang44/LeNet-from-Scratch.git\n",
        "\n",
        "#move inside the folder\n",
        "%cd LeNet-from-Scratch\n",
        "!mkdir -p MNIST"
      ],
      "metadata": {
        "id": "DdPzDl76WbS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef7e34d-292a-4751-fe70-871d5dcef560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LeNet-from-Scratch'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 134 (delta 1), reused 1 (delta 0), pack-reused 129 (from 1)\u001b[K\n",
            "Receiving objects: 100% (134/134), 1.21 MiB | 8.57 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n",
            "/content/LeNet-from-Scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.utils.prune as prune\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "BATCH_SIZE = 64 #scrutiniizes 64 images at a time\n",
        "EPOCHS = 5  #goes through the entire image set 5 times\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#check the presence of gpu, else use cpu\n",
        "\n",
        "\n",
        "#Filtering and narrowing down\n",
        "class LeNet300100(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet300100, self).__init__()\n",
        "        #28x28 pixels = 784 pixels\n",
        "        self.fc1 = nn.Linear(784, 300) #connect 784 pixels to 300 neurons to capture the patterns (arbitrary)\n",
        "        self.relu1 = nn.ReLU() #filter out unimportant noise(virtual [i.e. smudges] /mathematical)\n",
        "\n",
        "        self.fc2 = nn.Linear(300, 100) #narrows 300 neuron clues down to 100\n",
        "        self.relu2 = nn.ReLU() #more filtering\n",
        "\n",
        "        self.fc3 = nn.Linear(100, 10) #100 clues narrowed down to 0-9 (10 digits)\n",
        "\n",
        "#template for when an image set is received\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # flatten the image\n",
        "        x = self.relu1(self.fc1(x)) #1st filter\n",
        "        x = self.relu2(self.fc2(x)) #2nd filter\n",
        "        x = self.fc3(x) #final narrowing\n",
        "        return x #return the fina 0-9 values\n",
        "\n",
        "\n",
        "\n",
        "#download and batch the images\n",
        "def get_data():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),  #transform into tensor\n",
        "        transforms.Normalize((0.1307,), (0.3081,)) #standard MNIST normalization\n",
        "    ])\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True, transform=transform),\n",
        "        batch_size=BATCH_SIZE, shuffle=True)\n",
        "    #test the model's accuracy\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=False, transform=transform),\n",
        "        batch_size=1000, shuffle=False)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "\n",
        "#training the model (with training data)\n",
        "def train(model, train_loader):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001) #learning rate of 0.001 (small measured steps)\n",
        "    criterion = nn.CrossEntropyLoss() #measures error intensity\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"Training Epoch {epoch+1}/{EPOCHS}...\")\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward() #back propagation to find the exact error\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "#testing the model (with test data)\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    return 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "\n",
        "#weigh file size to prove the optimization did work/became smaller\n",
        "def get_file_size(file_path):\n",
        "    size_in_bytes = os.path.getsize(file_path)\n",
        "    return size_in_bytes / (1024 * 1024) # Convert to MB\n",
        "\n",
        "\n",
        "#visualisation\n",
        "def visualize_model_sparsity(model):\n",
        "    \"\"\"\n",
        "    Plots the weight matrices of the 3 layers to show the 'holes' created by pruning.\n",
        "    \"\"\"\n",
        "    #get the weights from the model\n",
        "    weights = [\n",
        "        model.fc1.weight.data.cpu().numpy(),\n",
        "        model.fc2.weight.data.cpu().numpy(),\n",
        "        model.fc3.weight.data.cpu().numpy()\n",
        "    ]\n",
        "    layer_names = ['Layer 1 (784 -> 300)', 'Layer 2 (300 -> 100)', 'Layer 3 (100 -> 10)']\n",
        "\n",
        "    # Create the plot\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    for i, ax in enumerate(axes):\n",
        "        weight_matrix = weights[i]\n",
        "\n",
        "        total_params = weight_matrix.size\n",
        "        zero_params = np.sum(weight_matrix == 0)\n",
        "        sparsity_percentage = 100 * zero_params / total_params\n",
        "\n",
        "        ax.imshow(np.abs(weight_matrix) > 0, cmap='viridis', aspect='auto', interpolation='nearest')\n",
        "\n",
        "        ax.set_title(f\"{layer_names[i]}\\nSparsity: {sparsity_percentage:.1f}%\")\n",
        "        ax.set_xlabel(\"Input Neurons\")\n",
        "        ax.set_ylabel(\"Output Neurons\")\n",
        "\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show() #show visualisation\n",
        "\n",
        "\n",
        "#main execution\n",
        "print(\"Setting up LeNet-300-100...\")\n",
        "train_loader, test_loader = get_data()\n",
        "model = LeNet300100().to(device)\n",
        "\n",
        "#training\n",
        "print(\"\\n[1] Training Baseline Model...\")\n",
        "train(model, train_loader)\n",
        "baseline_acc = test(model, test_loader)\n",
        "torch.save(model.state_dict(), \"model_baseline.pth\")\n",
        "baseline_size = get_file_size(\"model_baseline.pth\")\n",
        "\n",
        "#pruning\n",
        "print(\"\\n[2] Pruning Model (Removing 90% of connections)...\")\n",
        "# Since this model is all Linear, we can prune heavily (90% sparsity)\n",
        "parameters_to_prune = (\n",
        "    (model.fc1, 'weight'),\n",
        "    (model.fc2, 'weight'),\n",
        "    (model.fc3, 'weight'),\n",
        ")\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.9, # remove 90% of weights (detected through supervised learning + gradient descent)\n",
        ")\n",
        "\n",
        "\n",
        "for module, name in parameters_to_prune:\n",
        "    prune.remove(module, name)\n",
        "\n",
        "pruned_acc = test(model, test_loader)\n",
        "torch.save(model.state_dict(), \"model_pruned.pth\")\n",
        "pruned_size = get_file_size(\"model_pruned.pth\")\n",
        "\n",
        "#visualisation\n",
        "print(\"\\nGenerating Sparsity Visualization...\")\n",
        "visualize_model_sparsity(model)\n",
        "\n",
        "\n",
        "#quantisation of the pruned model (to reduce the precision)\n",
        "print(\"\\n[3] Quantizing Model (Float32 -> Int8)...\")\n",
        "# Move to CPU for quantization\n",
        "model_to_quantize = LeNet300100()\n",
        "model_to_quantize.load_state_dict(torch.load(\"model_pruned.pth\", map_location='cpu'))\n",
        "model_to_quantize.eval()\n",
        "\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model_to_quantize,\n",
        "    {nn.Linear},\n",
        "    dtype=torch.qint8\n",
        ")\n",
        "\n",
        "scripted_quantized_model = torch.jit.script(quantized_model)\n",
        "scripted_quantized_model.save(\"model_quantized.pt\")\n",
        "quantized_size = get_file_size(\"model_quantized.pt\")\n",
        "\n",
        "#results table\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"RESULTS FOR LENET-300-100 (MNIST)\")\n",
        "print(\"=\"*50)\n",
        "print(f\"{'Version':<20} | {'Size (MB)':<10} | {'Accuracy':<10}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'Baseline':<20} | {baseline_size:<10.4f} | {baseline_acc:.2f}%\")\n",
        "print(f\"{'Pruned (90%)':<20} | {pruned_size:<10.4f} | {pruned_acc:.2f}%\")\n",
        "print(f\"{'Pruned + Quantized':<20} | {quantized_size:<10.4f} | {'(Similar)'}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"COMPRESSION RATIO: {baseline_size / quantized_size:.1f}x smaller\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O65zjRoZwBX",
        "outputId": "99029693-1c31-4549-dde5-1c0d1b4361a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up LeNet-300-100...\n",
            "\n",
            "[1] Training Baseline Model...\n",
            "Training Epoch 1/5...\n",
            "Training Epoch 2/5...\n",
            "Training Epoch 3/5...\n",
            "Training Epoch 4/5...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Short Notes\n",
        "Filtering (ReLU): The Traffic Light\n",
        "\n",
        "Pruning: The Bulldozer\n",
        "\n",
        "The Data (Image): The Car"
      ],
      "metadata": {
        "id": "XNpEDNFMkNEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pruning alters the Pathways (The Map)\n",
        "\n",
        "Quantization alters the Content (The Precision)"
      ],
      "metadata": {
        "id": "sskXxp_4mxap"
      }
    }
  ]
}